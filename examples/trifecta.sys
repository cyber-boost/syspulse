# Trifecta: A cross-platform daemon set that runs on Windows, macOS, and Linux.
# Every command here uses cross-platform tools (Python, Node, etc.)
# so the same config works on all three operating systems.

[[daemon]]
name = "api-gateway"
command = ["python", "-m", "uvicorn", "gateway:app", "--host", "0.0.0.0", "--port", "8000"]
working_dir = "./services/gateway"
description = "API gateway — routes traffic to backend microservices"
stop_timeout_secs = 30
tags = ["cross-platform", "gateway", "python", "api"]

[daemon.env]
PYTHONUNBUFFERED = "1"
LOG_FORMAT = "json"
UPSTREAM_AUTH = "http://127.0.0.1:8001"
UPSTREAM_DATA = "http://127.0.0.1:8002"

[daemon.health_check]
type = "http"
target = "http://127.0.0.1:8000/healthz"
interval_secs = 15
timeout_secs = 5
retries = 3
start_period_secs = 5

[daemon.restart_policy]
policy = "always"
backoff_base_secs = 1
backoff_max_secs = 60

[daemon.resource_limits]
max_memory_bytes = 536870912    # 512 MB
max_cpu_percent = 40.0

[daemon.log_config]
max_size_bytes = 52428800       # 50 MB
retain_count = 7

[[daemon]]
name = "auth-service"
command = ["node", "dist/index.js"]
working_dir = "./services/auth"
description = "Authentication and authorization microservice"
stop_timeout_secs = 15
tags = ["cross-platform", "auth", "node", "api"]

[daemon.env]
NODE_ENV = "production"
PORT = "8001"
JWT_SECRET_FILE = "./secrets/jwt.key"
SESSION_TTL = "3600"

[daemon.health_check]
type = "http"
target = "http://127.0.0.1:8001/health"
interval_secs = 20
timeout_secs = 5
retries = 3
start_period_secs = 8

[daemon.restart_policy]
policy = "on_failure"
max_retries = 15
backoff_base_secs = 2
backoff_max_secs = 120

[daemon.resource_limits]
max_memory_bytes = 268435456    # 256 MB

[daemon.log_config]
max_size_bytes = 52428800       # 50 MB
retain_count = 5

[[daemon]]
name = "data-service"
command = ["python", "-m", "uvicorn", "data_api:app", "--host", "0.0.0.0", "--port", "8002"]
working_dir = "./services/data"
description = "Data service — CRUD operations and query engine"
stop_timeout_secs = 30
tags = ["cross-platform", "data", "python", "api"]

[daemon.env]
PYTHONUNBUFFERED = "1"
DATABASE_URL = "sqlite:///./data/app.db"
CACHE_TTL = "300"

[daemon.health_check]
type = "http"
target = "http://127.0.0.1:8002/healthz"
interval_secs = 30
timeout_secs = 5
retries = 3
start_period_secs = 10

[daemon.restart_policy]
policy = "on_failure"
max_retries = 10
backoff_base_secs = 2
backoff_max_secs = 300

[daemon.resource_limits]
max_memory_bytes = 1073741824   # 1 GB
max_cpu_percent = 60.0

[daemon.log_config]
max_size_bytes = 104857600      # 100 MB
retain_count = 10
compress_rotated = true

[[daemon]]
name = "task-worker"
command = ["python", "-m", "celery", "-A", "tasks", "worker", "--loglevel=info", "--concurrency=4"]
working_dir = "./services/workers"
description = "Background task worker for async jobs (emails, reports, etc.)"
tags = ["cross-platform", "worker", "python", "celery"]

[daemon.env]
PYTHONUNBUFFERED = "1"
BROKER_URL = "redis://127.0.0.1:6379/0"
RESULT_BACKEND = "redis://127.0.0.1:6379/1"

[daemon.health_check]
type = "command"
target = "python -m celery -A tasks inspect ping"
interval_secs = 60
timeout_secs = 15
retries = 3
start_period_secs = 15

[daemon.restart_policy]
policy = "always"
max_retries = 30
backoff_base_secs = 5
backoff_max_secs = 300

[daemon.resource_limits]
max_memory_bytes = 2147483648   # 2 GB

[[daemon]]
name = "frontend-dev"
command = ["node", "node_modules/.bin/vite", "--host", "0.0.0.0", "--port", "3000"]
working_dir = "./services/frontend"
description = "Vite dev server for the frontend SPA"
stop_timeout_secs = 10
tags = ["cross-platform", "frontend", "node", "vite"]

[daemon.env]
NODE_ENV = "development"
VITE_API_URL = "http://127.0.0.1:8000"

[daemon.health_check]
type = "tcp"
target = "127.0.0.1:3000"
interval_secs = 15
timeout_secs = 3
retries = 3
start_period_secs = 10

[daemon.restart_policy]
policy = "on_failure"
max_retries = 5
backoff_base_secs = 2
backoff_max_secs = 30

[[daemon]]
name = "db-backup"
command = ["python", "scripts/backup.py", "--compress", "--prune-days", "30"]
working_dir = "./services/data"
description = "Nightly database backup and old backup pruning"
schedule = "0 3 * * *"
tags = ["cross-platform", "backup", "scheduled"]

[daemon.restart_policy]
policy = "on_failure"
max_retries = 2
backoff_base_secs = 60
backoff_max_secs = 300
